{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center> ToolBox: Functions for Future Use </center></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_pval(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"Calculates the pairwise spearmanr correlation\n",
    "    coefficient and its corresponding p-values\"\"\"\n",
    "    \n",
    "    length = len(columns)\n",
    "    corr_matrix = np.empty(shape=(length, length), dtype=object)\n",
    "\n",
    "    for row_index, first_value in enumerate(columns):\n",
    "        col_vals = df[first_value]\n",
    "        for col_index, second_value in enumerate(columns):\n",
    "            second_col_vals = df[second_value]\n",
    "            if type(corr_matrix[col_index][row_index]) == list:\n",
    "                corr_matrix[row_index][col_index] = corr_matrix[col_index][row_index]\n",
    "            else:\n",
    "                corr, pval = spearmanr(col_vals, second_col_vals)\n",
    "                corr_matrix[row_index][col_index] = [np.round(corr, 3), np.round(pval, 3)]\n",
    "\n",
    "    return pd.DataFrame(corr_matrix, columns=columns, index=columns)\n",
    "\n",
    "def ci_table(weights: dict) -> pd.DataFrame:\n",
    "    \"\"\"Returns a DataFrame for confidence intervals \n",
    "    that have 4 columns:\n",
    "    1) Columns: Independent Variables\n",
    "    2) Lower Percentile\n",
    "    3) Upper Percentile\n",
    "    4) Median\n",
    "    \n",
    "    weights: a dictonary that have independet variables as keys and\n",
    "    their correponding bootstrapped samples as values\"\"\"\n",
    "    all_columns = predictor_columns\n",
    "    lower = []\n",
    "    upper = []\n",
    "    median = []\n",
    "    for i in all_columns:\n",
    "        all_weights = np.sort(weights[i])\n",
    "        lower.append(np.percentile(all_weights, 2.5))\n",
    "        upper.append(np.percentile(all_weights, 97.5))\n",
    "        median.append(np.percentile(all_weights, 50))\n",
    "\n",
    "    ci = pd.DataFrame({'Columns': all_columns,\n",
    "                       'Lower Percentile': lower,\n",
    "                       'Upper Percentile': upper,\n",
    "                       'Median': median})\n",
    "    return ci\n",
    "\n",
    "def ci_visualize(df: pd.DataFrame, figsize=(9, 3)):\n",
    "    \"\"\"Visualizes the Confidence Intervals of the regression weights\n",
    "    \n",
    "    df: DataFrame that has 4 columns: \n",
    "    1) Columns: Independent Variables\n",
    "    2) Lower Percentile\n",
    "    3) Upper Percentile\n",
    "    4) Median\"\"\"\n",
    "    sns.set_style('ticks')\n",
    "    plt.figure(figsize=figsize)\n",
    "    for lower,upper,median, z in zip(df['Lower Percentile'], \n",
    "                                     df['Upper Percentile'],\n",
    "                                     df['Median'],\n",
    "                                     range(len(df))):\n",
    "        if (lower == 0 or upper == 0) or (lower < 0 and upper > 0):\n",
    "            plt.plot((lower,upper),(z,z),'-|', color='black')\n",
    "            plt.scatter(median, z, color='black', s=15)\n",
    "        else:\n",
    "            plt.plot((lower,upper),(z,z),'-|', color='red')\n",
    "            plt.scatter(median, z, color='red', s=15)\n",
    "\n",
    "    plt.yticks(range(len(df)),list(df['Columns']))\n",
    "    plt.axvline(0, marker='|', linestyle='dashed', markersize=5, linewidth=1, color='gray')\n",
    "    plt.xlabel('Regression Weights', fontsize=13)\n",
    "    plt.title('Confidence Intervals', fontsize=15)\n",
    "    sns.despine()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_normalize(data: pd.DataFrame, predictor_columns: list, \n",
    "                    dependent_col: str, date_col = 'month_year', \n",
    "                    normalize='standardize', split_ratio=0.20):\n",
    "    \"\"\"\n",
    "    Splits the data and then normalizes it according to normalization type\n",
    "    Available types: 'standardize', 'time-window-standardize'\n",
    "    \"\"\"\n",
    "    assert normalize in ['standardize', 'time-window-standardize'], \"Available normalization types: 'standardize', 'time-window-standardize'\"\n",
    "    \n",
    "    #initializing empty dataframes\n",
    "    Xtrain = pd.DataFrame(columns=predictor_columns)\n",
    "    Xtest = pd.DataFrame(columns=predictor_columns)\n",
    "    ytrain = pd.Series(dtype='float64')\n",
    "    ytest = pd.Series(dtype='float64')\n",
    "    \n",
    "    time_windows = data[date_col].unique()\n",
    "    full_columns = predictor_columns + [date_col]\n",
    "    X = data[full_columns]\n",
    "    y = data[dependent_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio)\n",
    "    \n",
    "    if normalize == 'time-window-standardize':\n",
    "        for window in time_windows:\n",
    "            X_train_temp = X_train[X_train[date_col] == window].drop(columns=[date_col])\n",
    "            X_test_temp = X_test[X_test[date_col] == window].drop(columns=[date_col])\n",
    "            y_train_temp = y_train.loc[np.array(X_train[date_col] == window)]\n",
    "            y_test_temp = y_test.loc[np.array(X_test[date_col] == window)]\n",
    "\n",
    "            X_scaler = StandardScaler()\n",
    "            y_scaler = StandardScaler()\n",
    "\n",
    "            X_train_temp = pd.DataFrame(X_scaler.fit_transform(X_train_temp), columns=predictor_columns)\n",
    "            X_test_temp = pd.DataFrame(X_scaler.transform(X_test_temp), columns=predictor_columns)\n",
    "            y_train_temp = pd.Series(y_scaler.fit_transform(y_train_temp.to_numpy().reshape(-1, 1)).reshape(1, -1)[0])\n",
    "            y_test_temp = pd.Series(y_scaler.transform(y_test_temp.to_numpy().reshape(-1, 1)).reshape(1, -1)[0])\n",
    "\n",
    "            Xtrain = pd.concat([Xtrain, X_train_temp], ignore_index=True)\n",
    "            Xtest = pd.concat([Xtest, X_test_temp], ignore_index=True)\n",
    "            ytrain = pd.concat([ytrain, y_train_temp], ignore_index=True)\n",
    "            ytest = pd.concat([ytest, y_test_temp], ignore_index=True)\n",
    "            \n",
    "    else:\n",
    "        X_scaler = StandardScaler()\n",
    "        y_scaler = StandardScaler()\n",
    "        Xtrain = pd.DataFrame(X_scaler.fit_transform(X_train), columns=predictor_columns)\n",
    "        Xtest = pd.DataFrame(X_scaler.transform(X_test), columns=predictor_columns)\n",
    "        ytrain = pd.DataFrame(y_scaler.fit_transform(y_train), columns=[dependent_col])\n",
    "        ytest = pd.DataFrame(y_scaler.transform(y_test), columns=[dependent_col])\n",
    "        \n",
    "    return Xtrain, Xtest, ytrain, ytest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
